{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33cbc31-dc42-4987-a9e2-513e31dd92de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "from triton.testing import do_bench\n",
    "import torch._dynamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d742cd2-8f4b-40d5-a51e-36dacb9a11a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c588e4-db0c-4c73-8000-c51edad58d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_benchmark(fn):\n",
    "    exec_time, prctl20, prctl80 = do_bench(fn,warmup=100,rep=1000)\n",
    "    print(f\"Exec time (median): {exec_time}\")\n",
    "    print(f\"Exec time (20th percentile): {prctl20}\")\n",
    "    print(f\"Exec time (80th percentile): {prctl80}\\n\")\n",
    "    return exec_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe00915-2f6e-4a45-b33e-b309dd549dae",
   "metadata": {},
   "source": [
    "## 1. ResNet50 Speedup on NVIDIA A10G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306dae3d-ad53-442a-a62f-70c18d8567fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_batch(model, optimizer):\n",
    "    x = torch.randn(16, 3, 224, 224).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "    out.sum().backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e3d508d-75db-406b-92e2-6bedffd1510d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.resnet50().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d483ad8-2882-4ce5-a491-cb464b3e3bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet50 Eager mode\n",
      "Exec time (median): 50.456573486328125\n",
      "Exec time (20th percentile): 50.4313850402832\n",
      "Exec time (80th percentile): 50.50531768798828\n",
      "\n",
      "Resnet50 Compiled defaults\n",
      "Exec time (median): 46.913536071777344\n",
      "Exec time (20th percentile): 46.89653778076172\n",
      "Exec time (80th percentile): 46.9372673034668\n",
      "\n",
      "speedup:  7.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-4:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-2:\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Benchmark Eager\n",
    "print(\"Resnet50 Eager mode\")\n",
    "exec_time = run_benchmark(lambda: run_batch(model, optimizer))\n",
    "\n",
    "# Benchmark torch.compile defaults\n",
    "print(\"Resnet50 Compiled defaults\")\n",
    "opt_model = torch.compile(model)\n",
    "opt_exec_time = run_benchmark(lambda: run_batch(opt_model, optimizer))\n",
    "\n",
    "# Print speedups\n",
    "print(f\"speedup: {100*(exec_time-opt_exec_time) / opt_exec_time: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd3add7-7c03-4559-9109-8443700febdf",
   "metadata": {},
   "source": [
    "## 2. Custom model Speedup on NVIDIA A10G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca833c0-d383-45ce-9f31-06b126539376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(1024, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x).relu() ** 2\n",
    "        return self.fc2(x).relu() ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc293b4a-6634-4e66-95f0-1675ab363114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MLP().to(device)\n",
    "x = torch.randn(1024, 1024).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "020901c4-9054-4652-acaf-0232a31d0011",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec time (median): 0.7147520184516907\n",
      "Exec time (20th percentile): 0.7127040028572083\n",
      "Exec time (80th percentile): 0.7157760262489319\n",
      "\n",
      "Exec time (median): 0.6010879874229431\n",
      "Exec time (20th percentile): 0.6000639796257019\n",
      "Exec time (80th percentile): 0.6021119952201843\n",
      "\n",
      "speedup:  18.91%\n"
     ]
    }
   ],
   "source": [
    "# Benchmark Eager\n",
    "exec_time = run_benchmark(lambda: model(x).sum().backward())\n",
    "\n",
    "torch._dynamo.reset()\n",
    "# Benchmark torch.compile defaults\n",
    "cmodel = torch.compile(model, backend='inductor')\n",
    "opt_exec_time = run_benchmark(lambda: cmodel(x).sum().backward())\n",
    "\n",
    "# Print speedups\n",
    "print(f\"speedup: {100*(exec_time-opt_exec_time) / opt_exec_time: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a00c44-c096-4ae8-afe8-7937db196933",
   "metadata": {},
   "source": [
    "## 3. HuggingFace model Speedup on NVIDIA A10G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7a4eaae-8bc3-4a21-8147-a2d75e5fba3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "\n",
    "def run_inference(model, input_values):\n",
    "    \n",
    "    # retrieve logits\n",
    "    logits = model(input_values).logits\n",
    "    \n",
    "    # take argmax and decode\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d00a8f-4503-4fa7-90cd-263f693097da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baf2003e8ab49cca9c52c88ba8e14c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/158 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ce1004d67747d885b5390635fff5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c46f57ef4424b63a165423425872e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5234e1aa6f504a91b1d66cc10a2c5346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c075c6c9c63424781a7006dee4b604f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27eaa34b5cc5424faa543fb470ab76ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e2f484ed74461c892b44cf2ab8eac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset librispeech_asr_dummy/clean to /root/.cache/huggingface/datasets/patrickvonplaten___librispeech_asr_dummy/clean/2.1.0/f2c70a4d03ab4410954901bde48c54b85ca1b7f9bf7d616e7e2a72b5ee6ddbfc...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a8c6b33a3f40d7951adb0a22d345dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a044e0c9a4a24f4e9b8182b3150cf21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f4accd58444806abf78bc4d19ab800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset librispeech_asr_dummy downloaded and prepared to /root/.cache/huggingface/datasets/patrickvonplaten___librispeech_asr_dummy/clean/2.1.0/f2c70a4d03ab4410954901bde48c54b85ca1b7f9bf7d616e7e2a72b5ee6ddbfc. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "# load model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\").cuda()\n",
    "\n",
    "# load dummy dataset and read soundfiles\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "# tokenize\n",
    "input_values = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\", padding=\"longest\").input_values.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92d5578e-e793-48c2-b043-0a77d25d71c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec time (median): 30.511903762817383\n",
      "Exec time (20th percentile): 30.503211975097656\n",
      "Exec time (80th percentile): 30.539411544799805\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUTOTUNE bias_addmm(544x1024, 544x512, 512x1024)\n",
      "  triton_mm_1 0.0276s 100.0%\n",
      "  triton_mm_3 0.0276s 100.0%\n",
      "  triton_mm_2 0.0287s 96.4%\n",
      "  triton_mm_4 0.0287s 96.4%\n",
      "  bias_addmm 0.0287s 96.4%\n",
      "  triton_mm_0 0.0297s 93.1%\n",
      "  triton_mm_8 0.0328s 84.4%\n",
      "  triton_mm_10 0.0328s 84.4%\n",
      "  triton_mm_11 0.0348s 79.4%\n",
      "  triton_mm_5 0.0389s 71.1%\n",
      "AUTOTUNE bias_addmm(544x1024, 544x1024, 1024x1024)\n",
      "  triton_mm_13 0.0481s 100.0%\n",
      "  triton_mm_15 0.0481s 100.0%\n",
      "  triton_mm_14 0.0492s 97.9%\n",
      "  triton_mm_16 0.0492s 97.9%\n",
      "  triton_mm_12 0.0532s 90.4%\n",
      "  triton_mm_20 0.0532s 90.4%\n",
      "  bias_addmm 0.0543s 88.7%\n",
      "  triton_mm_22 0.0543s 88.7%\n",
      "  triton_mm_23 0.0594s 81.0%\n",
      "  triton_mm_18 0.0635s 75.8%\n",
      "AUTOTUNE bmm(16x544x64, 16x64x544)\n",
      "  triton_bmm_56 0.0553s 100.0%\n",
      "  triton_bmm_48 0.0553s 100.0%\n",
      "  triton_bmm_58 0.0573s 96.4%\n",
      "  triton_bmm_59 0.0584s 94.7%\n",
      "  triton_bmm_52 0.0604s 91.5%\n",
      "  triton_bmm_49 0.0604s 91.5%\n",
      "  triton_bmm_50 0.0604s 91.5%\n",
      "  triton_bmm_51 0.0614s 90.0%\n",
      "  bmm 0.0614s 90.0%\n",
      "  triton_bmm_55 0.0676s 81.8%\n",
      "AUTOTUNE bmm(16x544x544, 16x544x64)\n",
      "  triton_bmm_60 0.0594s 100.0%\n",
      "  triton_bmm_70 0.0604s 98.3%\n",
      "  triton_bmm_62 0.0614s 96.7%\n",
      "  triton_bmm_64 0.0614s 96.7%\n",
      "  triton_bmm_68 0.0625s 95.1%\n",
      "  triton_bmm_66 0.0625s 95.1%\n",
      "  triton_bmm_65 0.0635s 93.5%\n",
      "  bmm 0.0635s 93.5%\n",
      "  triton_bmm_61 0.0645s 92.1%\n",
      "  triton_bmm_63 0.0645s 92.1%\n",
      "AUTOTUNE bias_addmm(544x4096, 544x1024, 1024x4096)\n",
      "  bias_addmm 0.1720s 100.0%\n",
      "  triton_mm_88 0.1772s 97.1%\n",
      "  triton_mm_86 0.1782s 96.6%\n",
      "  triton_mm_84 0.1782s 96.6%\n",
      "  triton_mm_94 0.1792s 96.0%\n",
      "  triton_mm_87 0.1833s 93.9%\n",
      "  triton_mm_85 0.1833s 93.9%\n",
      "  triton_mm_91 0.1966s 87.5%\n",
      "  triton_mm_92 0.2058s 83.6%\n",
      "  addmm 0.2130s 80.8%\n",
      "AUTOTUNE bias_addmm(544x1024, 544x4096, 4096x1024)\n",
      "  triton_mm_97 0.1629s 100.0%\n",
      "  triton_mm_99 0.1638s 99.4%\n",
      "  triton_mm_98 0.1679s 97.0%\n",
      "  triton_mm_100 0.1679s 97.0%\n",
      "  bias_addmm 0.1700s 95.8%\n",
      "  triton_mm_104 0.1792s 90.9%\n",
      "  addmm 0.1884s 86.4%\n",
      "  triton_mm_106 0.1956s 83.3%\n",
      "  triton_mm_96 0.1966s 82.8%\n",
      "  triton_mm_102 0.2365s 68.9%\n",
      "AUTOTUNE bias_addmm(544x32, 544x1024, 1024x32)\n",
      "  bias_addmm 0.0164s 100.0%\n",
      "  triton_mm_2321 0.0184s 88.9%\n",
      "  triton_mm_2325 0.0184s 88.9%\n",
      "  triton_mm_2322 0.0184s 88.9%\n",
      "  addmm 0.0215s 76.2%\n",
      "  triton_mm_2324 0.0266s 61.5%\n",
      "  triton_mm_2316 0.0389s 42.1%\n",
      "  triton_mm_2326 0.0420s 39.0%\n",
      "  triton_mm_2327 0.0451s 36.4%\n",
      "  triton_mm_2317 0.0451s 36.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec time (median): 27.311792373657227\n",
      "Exec time (20th percentile): 27.307104110717773\n",
      "Exec time (80th percentile): 27.3222713470459\n",
      "\n",
      "speedup:  11.72%\n"
     ]
    }
   ],
   "source": [
    "exec_time = run_benchmark(lambda: run_inference(model, input_values))\n",
    "\n",
    "torch._dynamo.reset()\n",
    "model = torch.compile(model, mode=\"max-autotune\")\n",
    "opt_exec_time = run_benchmark(lambda: run_inference(model, input_values))\n",
    "\n",
    "# Print speedups\n",
    "print(f\"speedup: {100*(exec_time-opt_exec_time) / opt_exec_time: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6abb2e5a-966e-4e55-852b-a4c9f7eb03e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aot_ts_nvfuser',\n",
       " 'cudagraphs',\n",
       " 'inductor',\n",
       " 'ipex',\n",
       " 'nvprims_nvfuser',\n",
       " 'onnxrt',\n",
       " 'tvm']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._dynamo.list_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a7fc2-571d-4557-9744-43fb2b13f3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
